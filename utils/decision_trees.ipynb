{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "subdir = 'utils'\n",
    "path = os.path.join(parent_dir, subdir)\n",
    "sys.path.append(path)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_directory = os.path.abspath('../data')\n",
    "train_data = 'train.csv'\n",
    "test_data = 'test.csv'\n",
    "train_df = pd.read_csv(os.path.join(path_to_directory, train_data) )\n",
    "test_df = pd.read_csv(os.path.join(path_to_directory, test_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Treest\n",
    "\n",
    "Recursive partitioning. Regularisation reduce the depth of the tree.\n",
    "\n",
    "Advantages:\n",
    "- white box models\n",
    "\n",
    "Disadvantages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees\n",
    "\n",
    "class Decision_tree():\n",
    "    def __init__(self, data, target) -> None:\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.set = set()\n",
    "        \n",
    "    def all_splits(self):\n",
    "        columns = [col for col in self.data.columns if col not in ['PassengerId', self.target, 'Name', 'Ticket'] ]\n",
    "        gini_values = {}\n",
    "        for col  in columns:\n",
    "            for val in self.data[col].unique():\n",
    "                gini_weighted = self.split(col, val)\n",
    "                gini_values[col + '_split_' + str(val)] = gini_weighted\n",
    "                \n",
    "        # Find the minimum value of the dictionary and update the self.data\n",
    "        min_key = min(gini_values, key=gini_values.get)\n",
    "        col, val = min_key.split('_split_')\n",
    "        print(col, val)\n",
    "        return gini_values\n",
    "        \n",
    "            \n",
    "    def split(self, col, val):\n",
    "        \n",
    "        # Calculate probability for each node\n",
    "        cls1 = self.data[self.data[col] == val]\n",
    "        cls2 = self.data[self.data[col] != val]\n",
    "        prob_list, n1, n2 = self.calculate_probability(cls1, cls2)\n",
    "        \n",
    "        # Calculate gini_index for each node\n",
    "        g1, g2 = self.gini_index(prob_list)\n",
    "        \n",
    "        # Return weighted gini-impuritiny index\n",
    "        return self.gini_impurity_for_split(g1, g2, n1, n2)\n",
    "    \n",
    "    def calculate_probability(self, cls1, cls2):\n",
    "        ''''''\n",
    "        prob_cls1 = []\n",
    "        prob_cls2 = []\n",
    "        n1 = len(cls1)\n",
    "        n2 = len(cls2)\n",
    "        for val in cls1[self.target].unique():\n",
    "            temp_data = len(cls1[cls1[self.target] == val].copy(deep=True))\n",
    "            prob_cls1.append(temp_data / n1)\n",
    "\n",
    "        for val in cls2[self.target].unique():\n",
    "            value2 = len(cls2[cls2[self.target] == val].copy(deep=True))\n",
    "            prob_cls2.append(value2 / n2)\n",
    "        return [prob_cls1, prob_cls2], n1, n2\n",
    "        \n",
    "    def gini_index(self, prob_list):\n",
    "        g1 =  1 - np.sum([element **2 for element in prob_list[0]])\n",
    "        g2 =  1 - np.sum([element **2 for element in prob_list[1]])\n",
    "        return g1, g2\n",
    "        \n",
    "    def gini_impurity_for_split(self, g1, g2, n1, n2):\n",
    "        return n1/(n1+n2) * g1 + n2/(n1+n2) * g2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass 3\n",
      "Pclass 1\n",
      "Pclass 2\n",
      "Sex male\n",
      "Sex female\n",
      "Age 22.0\n",
      "Age 38.0\n",
      "Age 26.0\n",
      "Age 35.0\n",
      "Age 0.0\n",
      "Age 54.0\n",
      "Age 2.0\n",
      "Age 27.0\n",
      "Age 14.0\n",
      "Age 4.0\n",
      "Age 58.0\n",
      "Age 20.0\n",
      "Age 39.0\n",
      "Age 55.0\n",
      "Age 31.0\n",
      "Age 34.0\n",
      "Age 15.0\n",
      "Age 28.0\n",
      "Age 8.0\n",
      "Age 19.0\n",
      "Age 40.0\n",
      "Age 66.0\n",
      "Age 42.0\n",
      "Age 21.0\n",
      "Age 18.0\n",
      "Age 3.0\n",
      "Age 7.0\n",
      "Age 49.0\n",
      "Age 29.0\n",
      "Age 65.0\n",
      "Age 28.5\n",
      "Age 5.0\n",
      "Age 11.0\n",
      "Age 45.0\n",
      "Age 17.0\n",
      "Age 32.0\n",
      "Age 16.0\n",
      "Age 25.0\n",
      "Age 0.83\n",
      "Age 30.0\n",
      "Age 33.0\n",
      "Age 23.0\n",
      "Age 24.0\n",
      "Age 46.0\n",
      "Age 59.0\n",
      "Age 71.0\n",
      "Age 37.0\n",
      "Age 47.0\n",
      "Age 14.5\n",
      "Age 70.5\n",
      "Age 32.5\n",
      "Age 12.0\n",
      "Age 9.0\n",
      "Age 36.5\n",
      "Age 51.0\n",
      "Age 55.5\n",
      "Age 40.5\n",
      "Age 44.0\n",
      "Age 1.0\n",
      "Age 61.0\n",
      "Age 56.0\n",
      "Age 50.0\n",
      "Age 36.0\n",
      "Age 45.5\n",
      "Age 20.5\n",
      "Age 62.0\n",
      "Age 41.0\n",
      "Age 52.0\n",
      "Age 63.0\n",
      "Age 23.5\n",
      "Age 0.92\n",
      "Age 43.0\n",
      "Age 60.0\n",
      "Age 10.0\n",
      "Age 64.0\n",
      "Age 13.0\n",
      "Age 48.0\n",
      "Age 0.75\n",
      "Age 53.0\n",
      "Age 57.0\n",
      "Age 80.0\n",
      "Age 70.0\n",
      "Age 24.5\n",
      "Age 6.0\n",
      "Age 0.67\n",
      "Age 30.5\n",
      "Age 0.42\n",
      "Age 34.5\n",
      "Age 74.0\n",
      "SibSp 1\n",
      "SibSp 0\n",
      "SibSp 3\n",
      "SibSp 4\n",
      "SibSp 2\n",
      "SibSp 5\n",
      "SibSp 8\n",
      "Parch 0\n",
      "Parch 1\n",
      "Parch 2\n",
      "Parch 5\n",
      "Parch 3\n",
      "Parch 4\n",
      "Parch 6\n",
      "Fare 7.25\n",
      "Fare 71.2833\n",
      "Fare 7.925\n",
      "Fare 53.1\n",
      "Fare 8.05\n",
      "Fare 8.4583\n",
      "Fare 51.8625\n",
      "Fare 21.075\n",
      "Fare 11.1333\n",
      "Fare 30.0708\n",
      "Fare 16.7\n",
      "Fare 26.55\n",
      "Fare 31.275\n",
      "Fare 7.8542\n",
      "Fare 16.0\n",
      "Fare 29.125\n",
      "Fare 13.0\n",
      "Fare 18.0\n",
      "Fare 7.225\n",
      "Fare 26.0\n",
      "Fare 8.0292\n",
      "Fare 35.5\n",
      "Fare 31.3875\n",
      "Fare 263.0\n",
      "Fare 7.8792\n",
      "Fare 7.8958\n",
      "Fare 27.7208\n",
      "Fare 146.5208\n",
      "Fare 7.75\n",
      "Fare 10.5\n",
      "Fare 82.1708\n",
      "Fare 52.0\n",
      "Fare 7.2292\n",
      "Fare 11.2417\n",
      "Fare 9.475\n",
      "Fare 21.0\n",
      "Fare 41.5792\n",
      "Fare 15.5\n",
      "Fare 21.6792\n",
      "Fare 17.8\n",
      "Fare 39.6875\n",
      "Fare 7.8\n",
      "Fare 76.7292\n",
      "Fare 61.9792\n",
      "Fare 27.75\n",
      "Fare 46.9\n",
      "Fare 80.0\n",
      "Fare 83.475\n",
      "Fare 27.9\n",
      "Fare 15.2458\n",
      "Fare 8.1583\n",
      "Fare 8.6625\n",
      "Fare 73.5\n",
      "Fare 14.4542\n",
      "Fare 56.4958\n",
      "Fare 7.65\n",
      "Fare 29.0\n",
      "Fare 12.475\n",
      "Fare 9.0\n",
      "Fare 9.5\n",
      "Fare 7.7875\n",
      "Fare 47.1\n",
      "Fare 15.85\n",
      "Fare 34.375\n",
      "Fare 61.175\n",
      "Fare 20.575\n",
      "Fare 34.6542\n",
      "Fare 63.3583\n",
      "Fare 23.0\n",
      "Fare 77.2875\n",
      "Fare 8.6542\n",
      "Fare 7.775\n",
      "Fare 24.15\n",
      "Fare 9.825\n",
      "Fare 14.4583\n",
      "Fare 247.5208\n",
      "Fare 7.1417\n",
      "Fare 22.3583\n",
      "Fare 6.975\n",
      "Fare 7.05\n",
      "Fare 14.5\n",
      "Fare 15.0458\n",
      "Fare 26.2833\n",
      "Fare 9.2167\n",
      "Fare 79.2\n",
      "Fare 6.75\n",
      "Fare 11.5\n",
      "Fare 36.75\n",
      "Fare 7.7958\n",
      "Fare 12.525\n",
      "Fare 66.6\n",
      "Fare 7.3125\n",
      "Fare 61.3792\n",
      "Fare 7.7333\n",
      "Fare 69.55\n",
      "Fare 16.1\n",
      "Fare 15.75\n",
      "Fare 20.525\n",
      "Fare 55.0\n",
      "Fare 25.925\n",
      "Fare 33.5\n",
      "Fare 30.6958\n",
      "Fare 25.4667\n",
      "Fare 28.7125\n",
      "Fare 0.0\n",
      "Fare 15.05\n",
      "Fare 39.0\n",
      "Fare 22.025\n",
      "Fare 50.0\n",
      "Fare 8.4042\n",
      "Fare 6.4958\n",
      "Fare 10.4625\n",
      "Fare 18.7875\n",
      "Fare 31.0\n",
      "Fare 113.275\n",
      "Fare 27.0\n",
      "Fare 76.2917\n",
      "Fare 90.0\n",
      "Fare 9.35\n",
      "Fare 13.5\n",
      "Fare 7.55\n",
      "Fare 26.25\n",
      "Fare 12.275\n",
      "Fare 7.125\n",
      "Fare 52.5542\n",
      "Fare 20.2125\n",
      "Fare 86.5\n",
      "Fare 512.3292\n",
      "Fare 79.65\n",
      "Fare 153.4625\n",
      "Fare 135.6333\n",
      "Fare 19.5\n",
      "Fare 29.7\n",
      "Fare 77.9583\n",
      "Fare 20.25\n",
      "Fare 78.85\n",
      "Fare 91.0792\n",
      "Fare 12.875\n",
      "Fare 8.85\n",
      "Fare 151.55\n",
      "Fare 30.5\n",
      "Fare 23.25\n",
      "Fare 12.35\n",
      "Fare 110.8833\n",
      "Fare 108.9\n",
      "Fare 24.0\n",
      "Fare 56.9292\n",
      "Fare 83.1583\n",
      "Fare 262.375\n",
      "Fare 14.0\n",
      "Fare 164.8667\n",
      "Fare 134.5\n",
      "Fare 6.2375\n",
      "Fare 57.9792\n",
      "Fare 28.5\n",
      "Fare 133.65\n",
      "Fare 15.9\n",
      "Fare 9.225\n",
      "Fare 35.0\n",
      "Fare 75.25\n",
      "Fare 69.3\n",
      "Fare 55.4417\n",
      "Fare 211.5\n",
      "Fare 4.0125\n",
      "Fare 227.525\n",
      "Fare 15.7417\n",
      "Fare 7.7292\n",
      "Fare 12.0\n",
      "Fare 120.0\n",
      "Fare 12.65\n",
      "Fare 18.75\n",
      "Fare 6.8583\n",
      "Fare 32.5\n",
      "Fare 7.875\n",
      "Fare 14.4\n",
      "Fare 55.9\n",
      "Fare 8.1125\n",
      "Fare 81.8583\n",
      "Fare 19.2583\n",
      "Fare 19.9667\n",
      "Fare 89.1042\n",
      "Fare 38.5\n",
      "Fare 7.725\n",
      "Fare 13.7917\n",
      "Fare 9.8375\n",
      "Fare 7.0458\n",
      "Fare 7.5208\n",
      "Fare 12.2875\n",
      "Fare 9.5875\n",
      "Fare 49.5042\n",
      "Fare 78.2667\n",
      "Fare 15.1\n",
      "Fare 7.6292\n",
      "Fare 22.525\n",
      "Fare 26.2875\n",
      "Fare 59.4\n",
      "Fare 7.4958\n",
      "Fare 34.0208\n",
      "Fare 93.5\n",
      "Fare 221.7792\n",
      "Fare 106.425\n",
      "Fare 49.5\n",
      "Fare 71.0\n",
      "Fare 13.8625\n",
      "Fare 7.8292\n",
      "Fare 39.6\n",
      "Fare 17.4\n",
      "Fare 51.4792\n",
      "Fare 26.3875\n",
      "Fare 30.0\n",
      "Fare 40.125\n",
      "Fare 8.7125\n",
      "Fare 15.0\n",
      "Fare 33.0\n",
      "Fare 42.4\n",
      "Fare 15.55\n",
      "Fare 65.0\n",
      "Fare 32.3208\n",
      "Fare 7.0542\n",
      "Fare 8.4333\n",
      "Fare 25.5875\n",
      "Fare 9.8417\n",
      "Fare 8.1375\n",
      "Fare 10.1708\n",
      "Fare 211.3375\n",
      "Fare 57.0\n",
      "Fare 13.4167\n",
      "Fare 7.7417\n",
      "Fare 9.4833\n",
      "Fare 7.7375\n",
      "Fare 8.3625\n",
      "Fare 23.45\n",
      "Fare 25.9292\n",
      "Fare 8.6833\n",
      "Fare 8.5167\n",
      "Fare 7.8875\n",
      "Fare 37.0042\n",
      "Fare 6.45\n",
      "Fare 6.95\n",
      "Fare 8.3\n",
      "Fare 6.4375\n",
      "Fare 39.4\n",
      "Fare 14.1083\n",
      "Fare 13.8583\n",
      "Fare 50.4958\n",
      "Fare 5.0\n",
      "Fare 9.8458\n",
      "Fare 10.5167\n",
      "Cabin 0\n",
      "Cabin C85\n",
      "Cabin C123\n",
      "Cabin E46\n",
      "Cabin G6\n",
      "Cabin C103\n",
      "Cabin D56\n",
      "Cabin A6\n",
      "Cabin C23 C25 C27\n",
      "Cabin B78\n",
      "Cabin D33\n",
      "Cabin B30\n",
      "Cabin C52\n",
      "Cabin B28\n",
      "Cabin C83\n",
      "Cabin F33\n",
      "Cabin F G73\n",
      "Cabin E31\n",
      "Cabin A5\n",
      "Cabin D10 D12\n",
      "Cabin D26\n",
      "Cabin C110\n",
      "Cabin B58 B60\n",
      "Cabin E101\n",
      "Cabin F E69\n",
      "Cabin D47\n",
      "Cabin B86\n",
      "Cabin F2\n",
      "Cabin C2\n",
      "Cabin E33\n",
      "Cabin B19\n",
      "Cabin A7\n",
      "Cabin C49\n",
      "Cabin F4\n",
      "Cabin A32\n",
      "Cabin B4\n",
      "Cabin B80\n",
      "Cabin A31\n",
      "Cabin D36\n",
      "Cabin D15\n",
      "Cabin C93\n",
      "Cabin C78\n",
      "Cabin D35\n",
      "Cabin C87\n",
      "Cabin B77\n",
      "Cabin E67\n",
      "Cabin B94\n",
      "Cabin C125\n",
      "Cabin C99\n",
      "Cabin C118\n",
      "Cabin D7\n",
      "Cabin A19\n",
      "Cabin B49\n",
      "Cabin D\n",
      "Cabin C22 C26\n",
      "Cabin C106\n",
      "Cabin C65\n",
      "Cabin E36\n",
      "Cabin C54\n",
      "Cabin B57 B59 B63 B66\n",
      "Cabin C7\n",
      "Cabin E34\n",
      "Cabin C32\n",
      "Cabin B18\n",
      "Cabin C124\n",
      "Cabin C91\n",
      "Cabin E40\n",
      "Cabin T\n",
      "Cabin C128\n",
      "Cabin D37\n",
      "Cabin B35\n",
      "Cabin E50\n",
      "Cabin C82\n",
      "Cabin B96 B98\n",
      "Cabin E10\n",
      "Cabin E44\n",
      "Cabin A34\n",
      "Cabin C104\n",
      "Cabin C111\n",
      "Cabin C92\n",
      "Cabin E38\n",
      "Cabin D21\n",
      "Cabin E12\n",
      "Cabin E63\n",
      "Cabin A14\n",
      "Cabin B37\n",
      "Cabin C30\n",
      "Cabin D20\n",
      "Cabin B79\n",
      "Cabin E25\n",
      "Cabin D46\n",
      "Cabin B73\n",
      "Cabin C95\n",
      "Cabin B38\n",
      "Cabin B39\n",
      "Cabin B22\n",
      "Cabin C86\n",
      "Cabin C70\n",
      "Cabin A16\n",
      "Cabin C101\n",
      "Cabin C68\n",
      "Cabin A10\n",
      "Cabin E68\n",
      "Cabin B41\n",
      "Cabin A20\n",
      "Cabin D19\n",
      "Cabin D50\n",
      "Cabin D9\n",
      "Cabin A23\n",
      "Cabin B50\n",
      "Cabin A26\n",
      "Cabin D48\n",
      "Cabin E58\n",
      "Cabin C126\n",
      "Cabin B71\n",
      "Cabin B51 B53 B55\n",
      "Cabin D49\n",
      "Cabin B5\n",
      "Cabin B20\n",
      "Cabin F G63\n",
      "Cabin C62 C64\n",
      "Cabin E24\n",
      "Cabin C90\n",
      "Cabin C45\n",
      "Cabin E8\n",
      "Cabin B101\n",
      "Cabin D45\n",
      "Cabin C46\n",
      "Cabin D30\n",
      "Cabin E121\n",
      "Cabin D11\n",
      "Cabin E77\n",
      "Cabin F38\n",
      "Cabin B3\n",
      "Cabin D6\n",
      "Cabin B82 B84\n",
      "Cabin D17\n",
      "Cabin A36\n",
      "Cabin B102\n",
      "Cabin B69\n",
      "Cabin E49\n",
      "Cabin C47\n",
      "Cabin D28\n",
      "Cabin E17\n",
      "Cabin A24\n",
      "Cabin C50\n",
      "Cabin B42\n",
      "Cabin C148\n",
      "Embarked S\n",
      "Embarked C\n",
      "Embarked Q\n",
      "Embarked 0\n"
     ]
    }
   ],
   "source": [
    "decision_tree = Decision_tree(train_df, 'Survived')\n",
    "gini_dict = decision_tree.all_splits()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boosting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
