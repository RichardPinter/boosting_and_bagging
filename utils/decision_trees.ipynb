{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import opendatasets as od\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "subdir = 'utils'\n",
    "path = os.path.join(parent_dir, subdir)\n",
    "sys.path.append(path)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading titanic.zip to ./titanic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34.1k/34.1k [00:00<00:00, 1.19MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting archive ./titanic/titanic.zip to ./titanic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/titanic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     os\u001b[39m.\u001b[39;49mrename(src, real_dst)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/titanic' -> '/home/richard/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/data/titanic'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Download the dataset to the specified location\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     od\u001b[39m.\u001b[39mdownload(dataset_url)\n\u001b[0;32m----> 8\u001b[0m     shutil\u001b[39m.\u001b[39;49mmove(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mabspath(\u001b[39m'\u001b[39;49m\u001b[39m/titanic\u001b[39;49m\u001b[39m'\u001b[39;49m), path_to_directory)\n\u001b[1;32m     10\u001b[0m train_data \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     11\u001b[0m test_data \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/shutil.py:836\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m         rmtree(src)\n\u001b[1;32m    835\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         copy_function(src, real_dst)\n\u001b[1;32m    837\u001b[0m         os\u001b[39m.\u001b[39munlink(src)\n\u001b[1;32m    838\u001b[0m \u001b[39mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/usr/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/usr/lib/python3.10/shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m     os\u001b[39m.\u001b[39msymlink(os\u001b[39m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(src, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m             \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(dst, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m                 \u001b[39m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/titanic'"
     ]
    }
   ],
   "source": [
    "# Get the data from here https://www.kaggle.com/competitions/nyc-taxi-trip-duration/data\n",
    "path_to_directory = os.path.abspath('../data/titanic')\n",
    "if not os.path.exists(path_to_directory):\n",
    "    # URL of the dataset\n",
    "    dataset_url = 'https://www.kaggle.com/competitions/titanic/data'\n",
    "    # Download the dataset to the specified location\n",
    "    od.download(dataset_url)\n",
    "    shutil.move(os.path.abspath('titanic'), path_to_directory)\n",
    "\n",
    "train_data = 'train.csv'\n",
    "test_data = 'test.csv'\n",
    "train_df = pd.read_csv(os.path.join(path_to_directory, train_data))\n",
    "test_df = pd.read_csv(os.path.join(path_to_directory, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Treest\n",
    "\n",
    "Recursive partitioning. Regularisation reduce the depth of the tree.\n",
    "\n",
    "Advantages:\n",
    "- white box models\n",
    "\n",
    "Disadvantages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees\n",
    "\n",
    "class Decision_tree():\n",
    "    def __init__(self, data, target, max_depth) -> None:\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.seen = set()\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def all_iteration(self):\n",
    "        while self.max_depth >0:\n",
    "            self.best_split_for_single_iter()\n",
    "            print(self.seen)\n",
    "            self.max_depth -= 1 \n",
    "        return self.gini_values\n",
    "        \n",
    "    def best_split_for_single_iter(self):\n",
    "        columns = [col for col in self.data.columns if col not in ['PassengerId', self.target, 'Name', 'Ticket'] ]\n",
    "        self.gini_values = {}\n",
    "        for col  in columns:\n",
    "            for val in self.data[col].unique():\n",
    "                if (col, str(val)) not in self.seen:\n",
    "                    gini_weighted = self.split(col, val)\n",
    "                    self.gini_values[col + '_split_' + str(val)] = gini_weighted\n",
    "                else:\n",
    "                    print('dont calculate gini on these', col, val)\n",
    "                    \n",
    "        # Find the minimum value of the dictionary and update the self.data\n",
    "        min_key = min(self.gini_values, key=self.gini_values.get)\n",
    "        col, val = min_key.split('_split_')\n",
    "        print(col, val)\n",
    "        self.seen.add((col, str(val)))\n",
    "        return (col, val)\n",
    "        \n",
    "            \n",
    "    def split(self, col, val):\n",
    "        \n",
    "        # Calculate probability for each node\n",
    "        cls1 = self.data[self.data[col] == val]\n",
    "        cls2 = self.data[self.data[col] != val]\n",
    "        prob_list, n1, n2 = self.calculate_probability(cls1, cls2)\n",
    "        \n",
    "        # Calculate gini_index for each node\n",
    "        g1, g2 = self.gini_index(prob_list)\n",
    "        \n",
    "        # Return weighted gini-impuritiny index\n",
    "        return self.gini_impurity_for_split(g1, g2, n1, n2)\n",
    "    \n",
    "    def calculate_probability(self, cls1, cls2):\n",
    "        ''''''\n",
    "        prob_cls1 = []\n",
    "        prob_cls2 = []\n",
    "        n1 = len(cls1)\n",
    "        n2 = len(cls2)\n",
    "        for val in cls1[self.target].unique():\n",
    "            temp_data = len(cls1[cls1[self.target] == val].copy(deep=True))\n",
    "            prob_cls1.append(temp_data / n1)\n",
    "\n",
    "        for val in cls2[self.target].unique():\n",
    "            value2 = len(cls2[cls2[self.target] == val].copy(deep=True))\n",
    "            prob_cls2.append(value2 / n2)\n",
    "        return [prob_cls1, prob_cls2], n1, n2\n",
    "        \n",
    "    def gini_index(self, prob_list):\n",
    "        g1 =  1 - np.sum([element **2 for element in prob_list[0]])\n",
    "        g2 =  1 - np.sum([element **2 for element in prob_list[1]])\n",
    "        return g1, g2\n",
    "        \n",
    "    def gini_impurity_for_split(self, g1, g2, n1, n2):\n",
    "        return n1/(n1+n2) * g1 + n2/(n1+n2) * g2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = Decision_tree(train_df, 'Survived', 5)\n",
    "gini_dict = decision_tree.all_iteration()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boosting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
