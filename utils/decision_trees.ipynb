{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import opendatasets as od\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "from tqdm import tqdm\n",
    "import pysnooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "subdir = 'utils'\n",
    "path = os.path.join(parent_dir, subdir)\n",
    "sys.path.append(path)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from here https://www.kaggle.com/competitions/nyc-taxi-trip-duration/data\n",
    "path_to_directory = os.path.abspath('../data/titanic')\n",
    "if not os.path.exists(path_to_directory):\n",
    "    # URL of the dataset\n",
    "    dataset_url = 'https://www.kaggle.com/competitions/titanic/data'\n",
    "    # Download the dataset to the specified location\n",
    "    od.download(dataset_url)\n",
    "    shutil.move(os.path.abspath('titanic'), path_to_directory)\n",
    "\n",
    "train_data = 'train.csv'\n",
    "test_data = 'test.csv'\n",
    "train_df = pd.read_csv(os.path.join(path_to_directory, train_data))\n",
    "test_df = pd.read_csv(os.path.join(path_to_directory, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pysnooper.snoop()\n",
    "def create_something(iter):\n",
    "    x = 0\n",
    "    for i in range(iter):\n",
    "        x = x+i**34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_something(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Treest\n",
    "\n",
    "Recursive partitioning. Regularisation reduce the depth of the tree.\n",
    "\n",
    "Advantages:\n",
    "- white box models\n",
    "\n",
    "Disadvantages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees\n",
    "\n",
    "class Decision_tree():\n",
    "    def __init__(self, data, target, max_depth) -> None:\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.seen = set()\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def all_iteration(self):\n",
    "        while self.max_depth >0:\n",
    "            self.best_split_for_single_iter()\n",
    "            print(self.seen)\n",
    "            self.max_depth -= 1 \n",
    "        return self.gini_values\n",
    "    \n",
    "    def best_split_for_single_iter(self):\n",
    "        columns = [col for col in self.data.columns if col not in ['PassengerId', self.target, 'Name', 'Ticket'] ]\n",
    "        self.gini_values = {}\n",
    "        for col  in columns:\n",
    "            for val in self.data[col].unique():\n",
    "                if (col, str(val)) not in self.seen:\n",
    "                    gini_weighted = self.split(col, val)\n",
    "                    self.gini_values[col + '_split_' + str(val)] = gini_weighted\n",
    "                else:\n",
    "                    print('dont calculate gini on these', col, val)\n",
    "                    \n",
    "        # Find the minimum value of the dictionary and update the self.data\n",
    "        min_key = min(self.gini_values, key=self.gini_values.get)\n",
    "        col, val = min_key.split('_split_')\n",
    "        print(col, val)\n",
    "        self.seen.add((col, str(val)))\n",
    "        return (col, val)\n",
    "        \n",
    "            \n",
    "    def split(self, col, val):\n",
    "        \n",
    "        # Calculate probability for each node\n",
    "        cls1 = self.data[self.data[col] == val]\n",
    "        cls2 = self.data[self.data[col] != val]\n",
    "        prob_list, n1, n2 = self.calculate_probability(cls1, cls2)\n",
    "        \n",
    "        # Calculate gini_index for each node\n",
    "        g1, g2 = self.gini_index(prob_list)\n",
    "        \n",
    "        # Return weighted gini-impuritiny index\n",
    "        return self.gini_impurity_for_split(g1, g2, n1, n2)\n",
    "    \n",
    "    def calculate_probability(self, cls1, cls2):\n",
    "        ''''''\n",
    "        prob_cls1 = []\n",
    "        prob_cls2 = []\n",
    "        n1 = len(cls1)\n",
    "        n2 = len(cls2)\n",
    "        for val in cls1[self.target].unique():\n",
    "            temp_data = len(cls1[cls1[self.target] == val].copy(deep=True))\n",
    "            prob_cls1.append(temp_data / n1)\n",
    "\n",
    "        for val in cls2[self.target].unique():\n",
    "            value2 = len(cls2[cls2[self.target] == val].copy(deep=True))\n",
    "            prob_cls2.append(value2 / n2)\n",
    "        return [prob_cls1, prob_cls2], n1, n2\n",
    "        \n",
    "    def gini_index(self, prob_list):\n",
    "        g1 =  1 - np.sum([element **2 for element in prob_list[0]])\n",
    "        g2 =  1 - np.sum([element **2 for element in prob_list[1]])\n",
    "        return g1, g2\n",
    "        \n",
    "    def gini_impurity_for_split(self, g1, g2, n1, n2):\n",
    "        return n1/(n1+n2) * g1 + n2/(n1+n2) * g2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m decision_tree \u001b[39m=\u001b[39m Decision_tree(train_df, \u001b[39m'\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m gini_dict \u001b[39m=\u001b[39m decision_tree\u001b[39m.\u001b[39;49mall_iteration()\n",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m, in \u001b[0;36mDecision_tree.all_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_iteration\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth \u001b[39m>\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_split_for_single_iter()\n\u001b[1;32m     13\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen)\n\u001b[1;32m     14\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mDecision_tree.best_split_for_single_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[col]\u001b[39m.\u001b[39munique():\n\u001b[1;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m (col, \u001b[39mstr\u001b[39m(val)) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen:\n\u001b[0;32m---> 23\u001b[0m         gini_weighted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit(col, val)\n\u001b[1;32m     24\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgini_values[col \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_split_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(val)] \u001b[39m=\u001b[39m gini_weighted\n\u001b[1;32m     25\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mDecision_tree.split\u001b[0;34m(self, col, val)\u001b[0m\n\u001b[1;32m     39\u001b[0m cls1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[col] \u001b[39m==\u001b[39m val]\n\u001b[1;32m     40\u001b[0m cls2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[col] \u001b[39m!=\u001b[39m val]\n\u001b[0;32m---> 41\u001b[0m prob_list, n1, n2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_probability(cls1, cls2)\n\u001b[1;32m     43\u001b[0m \u001b[39m# Calculate gini_index for each node\u001b[39;00m\n\u001b[1;32m     44\u001b[0m g1, g2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgini_index(prob_list)\n",
      "Cell \u001b[0;32mIn[9], line 60\u001b[0m, in \u001b[0;36mDecision_tree.calculate_probability\u001b[0;34m(self, cls1, cls2)\u001b[0m\n\u001b[1;32m     57\u001b[0m     prob_cls1\u001b[39m.\u001b[39mappend(temp_data \u001b[39m/\u001b[39m n1)\n\u001b[1;32m     59\u001b[0m \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m cls2[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget]\u001b[39m.\u001b[39munique():\n\u001b[0;32m---> 60\u001b[0m     value2 \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(cls2[cls2[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget] \u001b[39m==\u001b[39;49m val]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m     61\u001b[0m     prob_cls2\u001b[39m.\u001b[39mappend(value2 \u001b[39m/\u001b[39m n2)\n\u001b[1;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m [prob_cls1, prob_cls2], n1, n2\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/frame.py:3752\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3750\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3751\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3752\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n\u001b[1;32m   3754\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3755\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3756\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3808\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   3810\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 3811\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3940\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   3941\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3942\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3943\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3946\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3947\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3948\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3950\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3924\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3925\u001b[0m         axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3926\u001b[0m         \u001b[39mand\u001b[39;00m indices\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3927\u001b[0m         \u001b[39mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   3928\u001b[0m         \u001b[39mand\u001b[39;00m is_range_indexer(indices, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[1;32m   3929\u001b[0m     ):\n\u001b[1;32m   3930\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 3932\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   3933\u001b[0m     indices,\n\u001b[1;32m   3934\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[1;32m   3935\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   3936\u001b[0m     convert_indices\u001b[39m=\u001b[39;49mconvert_indices,\n\u001b[1;32m   3937\u001b[0m )\n\u001b[1;32m   3938\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/internals/managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    960\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[1;32m    962\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 963\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[1;32m    964\u001b[0m     new_axis\u001b[39m=\u001b[39;49mnew_labels,\n\u001b[1;32m    965\u001b[0m     indexer\u001b[39m=\u001b[39;49mindexer,\n\u001b[1;32m    966\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    967\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    968\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    969\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/internals/managers.py:747\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    740\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    741\u001b[0m         indexer,\n\u001b[1;32m    742\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[1;32m    743\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n\u001b[1;32m    745\u001b[0m     )\n\u001b[1;32m    746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 747\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m    748\u001b[0m         blk\u001b[39m.\u001b[39mtake_nd(\n\u001b[1;32m    749\u001b[0m             indexer,\n\u001b[1;32m    750\u001b[0m             axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    751\u001b[0m             fill_value\u001b[39m=\u001b[39m(\n\u001b[1;32m    752\u001b[0m                 fill_value \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m blk\u001b[39m.\u001b[39mfill_value\n\u001b[1;32m    753\u001b[0m             ),\n\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    756\u001b[0m     ]\n\u001b[1;32m    758\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[1;32m    759\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/internals/managers.py:748\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    740\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    741\u001b[0m         indexer,\n\u001b[1;32m    742\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[1;32m    743\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n\u001b[1;32m    745\u001b[0m     )\n\u001b[1;32m    746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 748\u001b[0m         blk\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[1;32m    749\u001b[0m             indexer,\n\u001b[1;32m    750\u001b[0m             axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    751\u001b[0m             fill_value\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    752\u001b[0m                 fill_value \u001b[39mif\u001b[39;49;00m fill_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m blk\u001b[39m.\u001b[39;49mfill_value\n\u001b[1;32m    753\u001b[0m             ),\n\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    756\u001b[0m     ]\n\u001b[1;32m    758\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[1;32m    759\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/internals/blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    942\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[1;32m    946\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    949\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[39m#  these assertions\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m    952\u001b[0m     \u001b[39m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m    953\u001b[0m     \u001b[39m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Universe/2_richard_projects/2_6_boosting/boosting_and_bagging/boosting/lib/python3.10/site-packages/pandas/core/array_algos/take.py:104\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtype:\n\u001b[1;32m    100\u001b[0m         \u001b[39m# EA.take is strict about returning a new object of the same type\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[39m# so for that case cast upfront\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype)\n\u001b[0;32m--> 104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39;49m(arr, np\u001b[39m.\u001b[39;49mndarray):\n\u001b[1;32m    105\u001b[0m     \u001b[39m# i.e. ExtensionArray,\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[39m# includes for EA to catch DatetimeArray, TimedeltaArray\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_1d_only_ea_obj(arr):\n\u001b[1;32m    108\u001b[0m         \u001b[39m# i.e. DatetimeArray, TimedeltaArray\u001b[39;00m\n\u001b[1;32m    109\u001b[0m         arr \u001b[39m=\u001b[39m cast(\u001b[39m\"\u001b[39m\u001b[39mNDArrayBackedExtensionArray\u001b[39m\u001b[39m\"\u001b[39m, arr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decision_tree = Decision_tree(train_df, 'Survived', 5)\n",
    "gini_dict = decision_tree.all_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.plotting.backend = 'plotly'\n",
    "plt.scatter(train_df['Sex'], train_df['Fare'])\n",
    "# plt.scatter(train_df['Survived'], train_df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cmap = sns.light_palette('red', as_cmap =  True)\n",
    "\n",
    "train_df.style.background_gradient(cmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boosting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
